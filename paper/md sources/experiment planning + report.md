# Эксперимент

## Мысли

- `dice`-близость над `bag of nodes` хороша, но только в случае устойчивой кластеризации
    - было [A] [label: 5] [name: cambridge, leaving, need]  My departure site is ~~Cambridge~~ please.
    - стало [A] [label: 13] [name: centre, looking, town] My departure site is **Bend** please.
    - было [A] [label: 14] [name: food, italian, restaurant] I would like modern ~~European~~ food.
    - стало [A] [label: 0] [name: food, looking, restaurant] I would like modern **Asian** food.
    - т.е. из-за смещения в данных, возник отдельный кластер про кембридж/италию и это сделало кластеризацию не инвариантной к фактической информации, по-моему нехорошо, что кластер меняется при том же интенте
- `textattack` CLI
    - медленный
    - иногда непонятно какие модели он использует
    - принимает на вход только csv (хотелось бы json)
- с помощью замены синонимов можно генерить отрицательные примеры похожих диалогов, а с помощью добавления слов -- положительные
- LLM можно использовать для dialogue completion для генерации положительных примеров (убрать часть реплик и попросить бота заполнить)
- CLARE
    - вообще отличный метод для генерации положительных примеров, потому что он был создан как раз чтобы генерить положительные примеры, причем максимально нетривиальные (чтобы взломать модель)
    - но хотелось бы регулировать используемые трансформации, например, только вставки или любое другое подмножество, а не все сразу
    - но в textattack он слишком медленный: для обработки корпуса придется ждать несколько дней
    возможно нужно будет попробовать через api, мейби там есть какие-нибудь оптимизации или возможности для распараллеливания
    - в идеале самому написать на торче
- текущие итоги по `Inserter`
    - модели:
        - `microsoft/mpnet-base` отлично работает при `fill_utterance_level=2`, нетривиальные вставки, заодно даже немного взламывает кластеризацию
        - `xlnet-base-cased` и `xlnet-large-cased` вставляет одни предлоги и наречия, в целом глупее (причем при любой стратегии заполнения)
        - когда стоит использовать
            - mpnet: если не жалко времени (он раза в два медленее xlnet) и умещается в контекст из двух уттерансов 
            - xlnet: в остальных случаях
    - fraction:
        - если mpnet, то смело берем 0.5 и получаем отличные примеры
        - иначе 0.3
- как с помощью лламы аугментировать диалог:
    - маскировать уттерансы и просить лламу заполнить маски так, чтобы они подходили под контекст диалога
    - добавить маскированные уттерансы и попросить лламу заполнить их
    - попросить придумать начало/конец диалога
    - переписать диалог покороче/подлиннее
    - **ничего не удалось, не работает как часы: то лишние комментарии генерит, то нарушает json структуру**
    - **скорее всего нужно файнтюнить чтобы модель выдавала всегда одинаковый формат аутпута и лучше понимала что от нее требуют**
    - **наиболее продвинутой версией файнтюна мне видится комбинирование файнтюна с jsonformer**
- аугментация через шаффл:
    - выделять блоки (параграфы) и шаффлить их, а не отдельные предложения
    - например в мультивозе в одном диалоге часто речь сначала про ресторан а потом про такси, вот их можно шаффлить сто проц
    - то есть можно к примеру кластеризовать все уттерансы в датасете, и использовать разметку для сегментации диалога на смысловые части
    - можно посчитать попарные близости всех уттерансов в предложении и свапнуть пары самых близких
    - одну реплику состоящую из нескольких предложений можно разбить на несколько, не забыв указать говорящего, и наоборот

### Детектить корректный порядок реплик в диалоге с помощью NSP моделей

План работы:
- руками нагенерить шаффлы в диалогах: валидные и невалидные примеры
- собрать все эти NSP модели:
    - какие-нибудь с hf
    - собрать NSP датасет из диалоговых датасетов и обучить бейзлайн
- измерить NSP-скоры для сгенеренных шаффлов

Варианты NSP модели:
- спуллить ConveRT эмбеддинг уттерансов и обучить бустинг/ff-block/rnn на бинарную классификацию (correct/meaningless)
    - не забыть учесть спикера (обучить эмбеддинги для юзера и системы)
    - варианты пуллинга: min, max, avg, attention
- засунуть весь диалог в BiDeN и обучить CLS токен (или другая модель для dialogue modeling)
- два энкодера: один для предшествующего уттеранса, второй для последующего, максимизировать скалярное произведение если два уттеранса последовательные
    - энкодеры можно инициализировать из mpnet
    - можно файнтюнить энкодеры, а можно обучить проекторы
    - учесть контекст без дополнительного пересчета уттеранс-эмбеддингов можно так: считать выпуклую комбинацию текущего эмбеддинга и всех предыдущих
- **предсказывать ранг каждого уттеранса по данному диалогу: дать на вход уттерансы без информации об их порядке и попросить его восстановить (сделать лосс как в ListNet):**
    - каждый уттеранс кодируем мпнетом -> получили набор эмбеддингов
    - этот набор воспринимаем как токены, подаем на вход транформеру
    - хидден стейты с последнего слоя подаем в классификатор с одним выходом (это ранкер)
    - выходы для текущей последовательности подаем в софтмакс и воспринимаем полученные вероятности как ранги
    - применяем лосс из ListNet
    - сейчас надо реализовать
        - в уттеранс ранкере паддинг для батча из уттеранс эмбеддингов
        - в трансформере нулевой аттеншен для паддингов
        - прикинуть варианты распределения для `ranks_probs_true`
    - возможно нужно не прибавлять эмбеддинг говорящего а конкатенировать маленький кусочек

- кажется идеальным вариантом:
    - взять байден (или другую модель для dialogue modeling), зафайнтюнить его таким образом, чтобы на уровне диалога аттеншен был только между cls токенами каждого уттеранса, а внутри каждого уттеранса обычный аттеншен
    - закодить такую модель будет небыстро, поэтому сделать это стоит только после тестов над текущим вариантом уттеранс ранкера
    - можно и без байдена!
    - возьму MPNetModel из хф, подам в него тщательно задизайненую маску внимания, возможно в начало каждого уттеранса нужно добавить токен, отвечающий за говорящего

## Аугментации

**Вставка токенов.** Одним из простых, но эффективных способов аугментации текста является его удлинение с помощью вставки дополнительных токенов. Для этой цели мы добавляли служебный токен `<mask>` в случайные места диалогов и использовали трансформер-модели, обученные на задачу MLM, для заполнения этих масок. Вставка отвергалась, если предложенный моделью токен является лишь куском слова (BPE, Wordpiece) или если вероятность предсказания ниже порога, который подбирался вручную. Чтобы при вставке токена учесть контекст диалога, на вход MLM модели подается сразу несколько подряд идущих реплик либо диалог целиком.

**Замена токенов.** Метод идентичный предыдущему с точностью до того, что в данном методе нужно не добавить токен `<mask>` между токенами исходного диалога, а заменить часть токенов исходного диалога.

**Обратный перевод.** Перевод из оригинального языка на какой-то другой, затем обратный перевод на исходный язык. Использовались модели MT.

**Перемешивание реплик**. Предыдущие аугментации меняют диалог внутри отдельных фраз, поскольку являются методами, общими для произвольных текстовых данных. Кажется жизненно необходимым научиться менять порядок фраз в диалоге таким образом, чтобы получался валидный пример осмысленного диалога. Для этой цели мы предлагаем использовать модели, которые меряют близости между репликами внутри диалога. С помощью этих расстояний можно произвести кластеризацию реплик внутри каждого диалога. Эксперименты показали, что эти кластеры имеют смысл больших отдельных этапов диалога, которые можно пытаться перемешивать друг с другом.

**Укорачивание диалога.** Отдельные кластеры реплик внутри диалога можно отбрасывать, получая, тем самым, диалог с меньшим число реплик.

**Удлинение диалога.** Была обучена модель, которая по заданному списку реплик способна выстраивать их в диалог. Это трансформер, который принимает на вход текстовые эмбеддинги каждой реплики без указания информации о позиции реплики в исходном диалоге, и на выходе выдает ранги или вероятности, с помощью которых можно “отсортировать” реплики.

**Сохранение и изменение интента.** Перечисленные выше аугментации можно настроить таким образом, чтобы они сохраняли или изменяли интент. В качестве аугментаций, сохраняющих интент, мы использовали все операции, кроме замены токенов, которую использовали для подбора hard negative примеров.

### Диалоговый энкодер

**BERT.** В качестве бейзлайнового способа векторизации мы используем BERT без каких-либо модификаций. Мы подаем на вход диалог в виде `[CLS] ut1 [SEP] ut2 [SEP] ut3 [SEP]`, а на выходе усредняем векторы скрытого состояния токенов `SEP`.

**HSSA и BiDeN.** В качестве немного продвинутых диалоговых языковых моделей мы используем HSSA и BiDeN. 

Для обучения диалоговых энкодеров мы используем контрастивное обучение с in-batch negative примерами и hard negative примерами:
$$
\mathcal{L}=-\log{\exp(\cos(x_i,y_i))\over\sum_{j=1}^B\exp(\cos(x_i,y_j))},
$$
