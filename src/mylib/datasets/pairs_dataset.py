from torch.utils.data import Dataset
from typing import Literal
import math
import json
import os
from ..utils.data import ContextResponsePair


class ContextResponseDataset(Dataset):
    chunk_size = 2048
    def __init__(self, path, split: Literal['train', 'test', 'val'], fraction=1.):
        self.split = split
        self.path = path

        if split == 'train':
            max_n_chunks = 2556
        elif split == 'test' or split == 'val':
            max_n_chunks = 141

        if isinstance(fraction, float):
            self.fraction = min(1., max(0., fraction))
            self.n_chunks = math.ceil(self.fraction * max_n_chunks)
        elif isinstance(fraction, int):
            self.fraction = min(max_n_chunks, max(1, fraction))
            self.n_chunks = fraction
        else:
            raise ValueError('fraction must indicate number or fraction of chunks used (int or float)')

        self.len = self.n_chunks * self.chunk_size
    
    def __len__(self):
        return self.len
    
    def __getitem__(self, i):
        """
        Loads one chunk and returns one dialogue, represented with an object of the following schema:
        ```
        {
            "type": "object",
            "properties":
            {
                "context":
                {
                    "type": "array",
                    "items":
                    {
                        "type": "object",
                        "properties":
                        {
                            "utterance": {"type": "string"},
                            "speaker": {"type": "number"}
                        }
                    }
                },
                "target":
                {
                    "type": "object",
                    "properties":
                    {
                        "utterance": {"type": "string"},
                        "speaker": {"type": "number"}
                    }
                }
            }
        }
        ```"""
        i_chunk = math.floor(i / self.chunk_size)
        idx_within_chunk = i % self.chunk_size
        
        chunk_name = f'{i_chunk}.json'
        chunk_path = os.path.join(self.path, self.split, chunk_name)
        dct = json.load(open(chunk_path, 'r'))[idx_within_chunk]
        
        return ContextResponsePair.get_train_sample(dct)
